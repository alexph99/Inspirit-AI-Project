{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NQl0LLjCbwUBMqwggSsWtSgxGVlIe-PF","timestamp":1741376287019}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TiM6gYg0nhkY"},"source":["<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"]},{"cell_type":"markdown","metadata":{"id":"XFYAV890_btm"},"source":["# Goals\n","In this colab you will:\n","* Normalize and clean up your data.\n","* Explore your data using unsupervised learning methods.\n","* Build a model to predict crop yield from bacterial composition using a decision tree.\n","* Visualize and interpret a decision tree."]},{"cell_type":"code","metadata":{"id":"R-aCTwuSm0EQ","cellView":"form"},"source":["#@title ###Setup notebook.\n","\n","# Sample metadata\n","!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Sustainable%20Farming/sample_metadata.tsv\"\n","\n","# bacteria counts lognorm\n","!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Sustainable%20Farming/bacteria_counts_lognorm.csv\"\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.tree import plot_tree\n","\n","metadata = pd.read_table('sample_metadata.tsv')\n","metadata.index = ['farm_%i' % i for i in range(len(metadata))]\n","\n","bacteria_counts_lognorm = pd.read_csv('bacteria_counts_lognorm.csv', index_col=0)\n","print(\"Setup Successful.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AFDTOL8MklQO"},"source":["# A Starting Model\n","\n","Great! Now that we've cleaned up and explored our data a bit, it's time to build our first model. We are going to use something called a decision tree regression model (using the ```DecisionTreeRegressor``` scikit-learn model). You can check out the documentation on [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), and the schematic below described what a trained decision tree regression model looks like. Note that the model initialization, training, and testing follows the same framework as all of the other models we've trained. You've got this!\n"]},{"cell_type":"markdown","metadata":{"id":"78BfdUL-klQP"},"source":["<img src = \"https://i.ibb.co/ct3Cn6K/decision-tree-regressor.jpg\" height=400/>"]},{"cell_type":"markdown","metadata":{"id":"vT4TwJQ4kJfP"},"source":["####**Exercise: Just to review, in our model to predict crop-yield from bacterial composition of soil, what will we be using as *features* (i.e. X data or independent variable)  and *labels* (i.e. Y data or dependent variable)?**\n"]},{"cell_type":"code","metadata":{"id":"9OYn11A5klQQ","cellView":"form"},"source":["_features_ = '' #@param {type:\"string\"}\n","_labels_ = '' #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VqDRsTMAklQQ"},"source":["####**Exercise: Fill out the code below to split your data into testing and training, train your ```DecisionTreeRegressor``` model, and make predictions on your test data.** Don't worry about computing model accuracy just yet."]},{"cell_type":"code","metadata":{"id":"RCVpmK4aklQQ"},"source":["# We helped you define your X and y data here.\n","X = bacteria_counts_lognorm\n","y = metadata['crop_yield']\n","\n","# Next, split your data into testing and training.\n","X_train, X_test, y_train, y_test = train_test_split(X, y)\n","\n","# Now, initialize your model (just use the default settings for now!)\n","model = None ### FILL ME IN ####\n","\n","# Train your model with the training data. Hint: use the model.fit() function\n","### FILL ME IN ####\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0WOw4g-klQR"},"source":["#@title Example Solution\n","# We helped you define your X and y data here.\n","X = bacteria_counts_lognorm\n","y = metadata['crop_yield']\n","\n","# Next, split your data into testing and training.\n","X_train, X_test, y_train, y_test = train_test_split(X, y)\n","\n","# Now, initialize your model (just use the default settings for now!)\n","model = DecisionTreeRegressor()\n","\n","# Train your model with the training data.\n","model.fit(X_train, y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXLuiS7yqP6s"},"source":["#### **Exercise: Now, make predictions on your testing dataset so that we can take a look at model performance. Don't compute accuracy just yet though!**"]},{"cell_type":"code","metadata":{"id":"02aVSDoYqXmE"},"source":["# Make predictions on your test data. Hint: use the model.predict() function.\n","preds = None  ## FILL ME IN ###"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6HLIQC3qdxb"},"source":["#@title Example Solution\n","# Make predictions on your test data. (Don't try to compute accuracy just yet...)\n","preds = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V7OEDV_XklQR"},"source":["#### **Exercise: Run the code below to visualize the performance of your model, and discuss how you feel your model performed.**\n","\n","**(Optional):** Can you plot your model's line of best fit to see how closely\n","predictions matched yields?\n"]},{"cell_type":"code","metadata":{"id":"w1L4L4G9klQR"},"source":["plt.plot(y_test, preds, '.')\n","plt.xlabel('True crop yields')\n","plt.ylabel('Predicted crop yields')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82Gb8pNjklQS"},"source":["**Discuss: Why can't we compute an 'accuracy score' for this model like we did for many of the models we worked on last week? What are some other ways we could evaluate how well our model performed?** (Stay tuned for the next notebook!)"]},{"cell_type":"markdown","metadata":{"id":"-CusY9Gfp87M"},"source":["# Visualizing and Interpreting Decision Trees\n","\n","Decision trees are really great models because they can be easily visualized and interpreted. ***Interpreting a model*** means understanding why the model is making its decisons/predictions. Models that are tricky to interpret are sometimes called ***black-box models***, because it's tough to really grasp what the algorithm inside is doing. Some people consider neural networks somewhat of a black-box and a major field of AI research is finding ways to interpret neural networks.\n","\n","####**Exercise: What are some reasons that machine learning researchers (and policy makers for that matter) are so concerned about model interpretability?**\n","\n"]},{"cell_type":"code","metadata":{"id":"uRRfLQeKRz-c","cellView":"form"},"source":["_1_ = '' #@param {type:\"string\"}\n","_2_ = '' #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gkLkgli4RtJ1"},"source":["\n","## Visualization\n","One way we can help understand what a decision tree is doing under the hood is by visualization. We can visualize the decision tree our model learned using some cool graphics libraries in python. Let's try this out.\n","\n","### A Small Toy Model\n"]},{"cell_type":"markdown","metadata":{"id":"fhmO98ZH8g8Z"},"source":["####**Exercise: Let's quickly train a very small model using only 3 features so we can practice visualizing a decision tree. Run the following code to train a 3-feature model.**"]},{"cell_type":"code","metadata":{"id":"gK0xcjOY8nWq"},"source":["# Now, initialize your model (just use the default settings for now!)\n","small_model = DecisionTreeRegressor(max_depth=3, max_leaf_nodes=4)\n","\n","# Train your model with the training data, using only three features.\n","small_model.fit(X_train[['Actinocorallia', 'Clostridium sensu stricto 10', 'Blastocatellaceae']], y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNHa3VvFAmG-"},"source":["####**Exercise: Now run the following code to visualize your model.**"]},{"cell_type":"code","metadata":{"id":"vxGQX5MbrSDx"},"source":["plt.figure(figsize=(20,20))\n","plot_tree(small_model, feature_names=['Actinocorallia', 'Clostridium sensu stricto 10', 'Blastocatellaceae'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xb_f5OT4_UsV"},"source":["####**Exercise: Answer the following questions as a group:**\n","1. What does each \"box\" mean?\n","2. What does each line mean?\n","3. What does the the first line (with the inequality sign) in each box mean?\n","4. What do MSE, samples, and value mean?\n","5. What do you think the very bottom row (the leaves) of your decision tree look like?\n","\n"]},{"cell_type":"code","metadata":{"id":"MJSojmLmpXXB","cellView":"form"},"source":["#@title\n","_1_ = \"\" #@param {type:\"string\"}\n","_2_ = \"\" #@param {type:\"string\"}\n","_3_ = \"\" #@param {type:\"string\"}\n","_4_ = \"\" #@param {type:\"string\"}\n","_5_ = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Instructor Solution**\n","<details><summary>click to reveal!</summary>\n","\n","1. **What does each “box” mean?**\n","   - A node in the decision tree.\n","2. **What does each line mean?**\n","   - A branch in the decision tree.\n","3. **What does the first line (with the inequality sign) in each box mean?**\n","   - The condition for which a decision is made. If the condition is true (<=), the path goes left; if false, it goes right.\n","4. **What do MSE, samples, and value mean?**\n","   - **MSE (Mean Squared Error):** The averaged error of the samples falling into that node, calculated as the difference between the actual values and the model’s predictions.\n","   - **Samples:** The number of crop samples fitting that category. Starting with 1008 at the root, samples are filtered into different leaf nodes, which all add up to 1008.\n","   - **Value:** The output value the decision tree predicts for the given samples at that node, in this case, crop yield.\n","5. **What do you think the very bottom row (the leaves) of your decision tree look like?**\n","   - The leaves contain labels for the value of crop yield and indicate how many samples were given that label based on the decisions made throughout the tree.\n"],"metadata":{"id":"qtHo57TEuQRR"}},{"cell_type":"markdown","metadata":{"id":"gGWZ-FatBaNe"},"source":["####**Exercise: Given the decision tree visualization, what do you think ```max_depth=4``` and ```max_leaf_nodes=3``` mean?** What happens if you change those values?\n"]},{"cell_type":"code","metadata":{"id":"IBCYqO_tBZUJ","cellView":"form"},"source":["#@title\n","max_depth = \"\" #@param {type:\"string\"}\n","max_leaf_nodes = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-3xXG2KEMdC"},"source":["### Full Model\n","\n","Let's go ahead and check out the decision tree trained on our full model (without any set values of ```max_depth``` or ```max_leaf_nodes```.\n","\n","#### **Exercise: Use plot_tree to visualize your full decision tree model.** It should be saved in ```model```, and you can use ```feature_names=X.columns ```."]},{"cell_type":"code","metadata":{"id":"68ViKumVIUQQ"},"source":["plt.figure(figsize=(20,20))\n","# FILL IN ###\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aq9MjiQMJBHx","cellView":"form"},"source":["#@title Example Solution\n","# Don't worry if this takes a while to run!\n","plt.figure(figsize=(20,20))\n","plot_tree(model, feature_names=X.columns)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y9Ops37VtQs4"},"source":["That's a big tree!\n","\n","###**Exercise: Add in ```max_depth=3``` to the ```plot_tree``` function to just zoom in on the highest level branches to get more detail.**\n"]},{"cell_type":"code","metadata":{"id":"CK21-HMIrTgY"},"source":["plt.figure(figsize=(20,20))\n","### FILL IN ###\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhW_y2uBJhNH","cellView":"form"},"source":["#@title Example Solution\n","plt.figure(figsize=(20,20))\n","plot_tree(model, max_depth=3, feature_names=X.columns)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bc_j95R7wxvT"},"source":["Let's try out different values for ```max_depth``` in the cell above!\n","####**Discuss:** What are some similarities and differences you observe?"]},{"cell_type":"markdown","metadata":{"id":"3JPOYTumADbI"},"source":["## Interpreting Decision Trees\n","\n","Another way to help us *interpret* the decision tree (or figure out what the decision tree is doing and why) is to see which features were the most important in the model.\n","\n","### Feature Importances\n","\n","Recall the equation that linear regression is fitting:\n","\n","$\n","Y = \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + ...\n","$\n","\n","The $\\beta$s correspond to the weights of features, or how important each feature is to the model. In decision trees & random forests, we don't fit to a linear equation so we don't have feature weight coefficients per say, but we can calculate something called **feature importances**. Feature importances are similar to weights, in that they have to do with how well a certain feature helped with the prediction.  \n","\n","We can access the values of the feature importances after training with ```model.feature_importances_```.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vVsJFQieAwYC"},"source":["####**Exercise: Fill in the code below to organize your feature importances into a nice dataframe.  Go ahead and look at the first *10* rows of the dataframe.**"]},{"cell_type":"code","metadata":{"id":"hjIwJxx7Av4P"},"source":["## Create a feature_importance dataframe.\n","feature_importance_dataframe = pd.DataFrame(model.feature_importances_, columns=['feature_importance'])\n","feature_importance_dataframe.index = X.columns\n","feature_importance_dataframe.head() # Fill in to check top 10 rows!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNMk04adKr_l","cellView":"form"},"source":["#@title Example Solution\n","## Create a feature_importance dataframe.\n","feature_importance_dataframe = pd.DataFrame(model.feature_importances_, columns=['feature_importance'])\n","feature_importance_dataframe.index = X.columns\n","feature_importance_dataframe.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1F4ZMDIK4HR"},"source":["#### **Exercise: Fill in the code below to find the top 5 most important features to your model.** Hint: Use the ```.sort_values('feature_importance', ascending=False)``` function to on your ```feature_importance_dataframe``` to sort your data from greatest to least important features, and then use ```.head()``` to see the top 5."]},{"cell_type":"code","metadata":{"id":"ufG9Un9XK_le"},"source":["# Use the .sort_values() function to sort the rows of your dataframe.\n","feature_importance_dataframe_sorted = feature_importance_dataframe ### FILL IN ###\n","\n","# Use the .head() function to take a look at the top 5 most important features.\n","feature_importance_dataframe_sorted ### FILL IN ####"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rigKgQolLqMf","cellView":"form"},"source":["#@title Example Solution\n","# Use the .sort_values() function to sort the rows of your dataframe.\n","feature_importance_dataframe_sorted = feature_importance_dataframe.sort_values('feature_importance', ascending=False)\n","\n","#Use the .head() function to take a look at the top 5 most important features.\n","feature_importance_dataframe_sorted.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmjc2vtKPhTq"},"source":["<img src=\"https://www.growingproduce.com/wp-content/uploads/2016/03/Bacterial-spot-symptoms-on-pepper-leaves-for-web.jpg\" width=400>"]},{"cell_type":"markdown","metadata":{"id":"iik6yUrxB438"},"source":["####**Exercise: Do a quick google search on a couple of the most important bacteria and briefly describe the environments/ecosystems they live in and their function.**"]},{"cell_type":"code","metadata":{"cellView":"form","id":"6E6g5Xw9_UT6"},"source":["bacteria_1 = '' #@param {type:\"string\"}\n","bacteria_2 = '' #@param {type:\"string\"}\n","bacteria_3 = '' #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCt8DTf1CrOo"},"source":["# Review: Experimenting with Hyperparameters\n","\n","Let's practice the machine learning pipeline one more time!  Using ```X_train```,  ```X_test```, ``y_train``, and ```y_test``` (these should be already defined for you), (1) build and train a decision tree to predict crop yield from bacterial composition, (2) compute the test predictions and (3) visualize your decision tree.  Try changing different *hyperparameters* of the model such as number of leaves, branches, and splits in your model using the following initialization:\n","\n","```\n","model = DecisionTreeRegressor(max_depth=, max_leaf_nodes=)\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qtyrnF3CM31n"},"source":["####**Exercise: Step 1: Train your model**"]},{"cell_type":"code","metadata":{"id":"BBvMACmxgTty"},"source":["# Initialize your model (just use the default settings for now!)\n","### FILL IN HERE ###\n","\n","# Train your model with the training data.\n","### FILL IN HERE ###\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxfy9_Z2vupU","cellView":"form"},"source":["#@title Example Solution\n","# Now, initialize your model (just use the default settings for now!)\n","model = DecisionTreeRegressor(max_depth=100, max_leaf_nodes=200)\n","\n","# Now, initialize your model (just use the default settings for now!)\n","model.fit(X_train, y_train)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1nmrDV9NCsK"},"source":["####**Exercise: Step 2: Make predictions on your testing data and plot predictions against true crop yields.**\n","\n","**(Optional):** Can you plot your model's line of best fit to see how closely\n","predictions matched yields?"]},{"cell_type":"code","metadata":{"id":"OYSFi_STNAT9"},"source":["# Make predictions on your test data. (Don't try to compute accuracy just yet...)\n","### FILL IN HERE ###\n","\n","# Plot your predictions against the true crop yields of the test data.\n","### FILL IN HERE ###\n","\n","plt.xlabel('True crop yields')\n","plt.ylabel('Predicted crop yields')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"vLQXoOVqNJNI"},"source":["#@title Example Solution\n","\n","# Make predictions on your test data. (Don't try to compute accuracy just yet...)\n","preds = model.predict(X_test)\n","\n","# Plot your predictions against the true crop yields of the test data\n","plt.plot(y_test, preds, '.')\n","plt.xlabel('True crop yields')\n","plt.ylabel('Predicted crop yields')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MlG48ZGXNzm9"},"source":["####**Exercise: Step 3: Visualize your decision tree.** Note: It is ok just to look at the first few branches by setting ```max_depth=3``` in ```plot_tree()```."]},{"cell_type":"markdown","metadata":{"id":"J9Jh4evVrZzr"},"source":["####**Exercise: Once again, run the following code to plot your predictions against the true crop yields of the test data**"]},{"cell_type":"code","metadata":{"id":"agMwResXqtou"},"source":["plt.figure(figsize=(10,10))\n","\n","# Use plot_tree to visualize the first few branches of your decision tree.\n","### FILL IN ####\n","\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"WHHm1NOnN-K_"},"source":["#@title Example Solution\n","plt.figure(figsize=(20,20))\n","\n","# Use plot_tree to visualize the first few branches of your decision tree.\n","plot_tree(model, max_depth=3, feature_names=X.columns)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EyVsHjOlhf5P"},"source":["**Discuss: How did different values of hyperparameters affected your model performance? Which model did you like the best?**"]},{"cell_type":"markdown","metadata":{"id":"9F3AVkrUtiKk"},"source":["## **Awesome work so far!**\n","In the next notebook, we will be using our model in order to make policy decisions. So to wrap up, **discuss the following:  Why might we prefer simple machine learning models like decision trees instead of more sophisticated models like neural networks when it comes to policy decisions (lke deciding which areas the government should subsidize for farming?)?**\n","\n","<img src = \"https://media.istockphoto.com/photos/shortcut-from-point-a-to-point-b-concept-picture-id1138022429?k=6&m=1138022429&s=612x612&w=0&h=5t-vKtjIkKqLY9SnRXNdLmR8T-PLzYJTSo1kNrdCnoY=\" width=400/>\n"]}]}